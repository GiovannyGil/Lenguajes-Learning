{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9355f0",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks\n",
    "### Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531c7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "inicio = time.time()\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a20def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.python.keras.models import Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from skimage.transform import resize\n",
    "#from torchvision.transforms import Resize\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6489506",
   "metadata": {},
   "source": [
    "## Cargar set de Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40235ab",
   "metadata": {},
   "source": [
    "### Separar imagenes para validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5a15d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'imgs60X'\n",
    "valid_dir = 'val60X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cba1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_aleat_image(path):\n",
    "    \n",
    "    # Select random file\n",
    "    #random_folder = random.choice(os.listdir(path))\n",
    "    random_file = random.choice(\n",
    "    os.listdir(os.path.join(path)))\n",
    "\n",
    "    # Create image path\n",
    "    image_path = os.path.join(path, random_file)\n",
    "    image_path = os.path.normpath(image_path)\n",
    "\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f83808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jorge/EjemplosPY/WoodTracer/Wood60X/data2_temp'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Crear data temporal\n",
    "ruta_path = os.getcwd() + os.sep\n",
    "origen = ruta_path + 'data2'\n",
    "destino = ruta_path + 'data2_temp'\n",
    "shutil.copytree(origen, destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a99dc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  /home/jorge/EjemplosPY/WoodTracer/Wood60X/data2_temp/\n"
     ]
    }
   ],
   "source": [
    "#dirname = os.path.join(os.getcwd(), 'data2_temp')\n",
    "imgpath = destino + os.sep\n",
    "ruta1 = ruta_path + data_dir + os.sep\n",
    "ruta2 = ruta_path + valid_dir + os.sep\n",
    "#dirname1 = os.path.join(os.getcwd(), 'val60X')\n",
    "#imgpath1 = dirname1 + os.sep\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdaf4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for dirname in dirnames:\n",
    "        path1 = root + dirname\n",
    "        folder_nomber = path1.split('/')[7]\n",
    "        path_dir = ruta2 + folder_nomber + os.sep\n",
    "        os.mkdir(path_dir)\n",
    "        for i in range(3):\n",
    "            image_path = select_aleat_image(path1)\n",
    "            name_image = image_path.split('/')[8]\n",
    "            new_path = path_dir + dirname + '-' + name_image\n",
    "            # Mover archivo\n",
    "            os.rename(image_path, new_path)\n",
    "\n",
    "# Funcion de Augmantation data\n",
    "# tomar una imagen aleatoriamente y hacerle cambios, con \"augmentation data\" y guardar las imagenes\n",
    "# esto hasta que la cantidad de cada categoria sea igual a 1000\n",
    "\n",
    "origen1 = ruta_path + 'data2_temp'\n",
    "destino1 = ruta_path + 'imgs60X'\n",
    "shutil.copytree(origen1, destino1)\n",
    "shutil.rmtree(origen1, ignore_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f8782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leyendo imagenes de  /home/jorge/EjemplosPY/WoodTracer/Wood60X/imgs60X/\n",
      "en la Categoría: Ficus_sp, el total de imagenes es: 10\n",
      "en la Categoría: Ocotea_bofo, el total de imagenes es: 10\n",
      "en la Categoría: Qualea_acuminata, el total de imagenes es: 10\n",
      "en la Categoría: Tabebuia_rosea, el total de imagenes es: 10\n",
      "en la Categoría: Cariniana_pyriformis, el total de imagenes es: 10\n",
      "en la Categoría: Tectona_grandis, el total de imagenes es: 10\n",
      "en la Categoría: Pithecellobium_dulce, el total de imagenes es: 10\n",
      "en la Categoría: Peltogyne_purpurea, el total de imagenes es: 10\n",
      "en la Categoría: Anacardium_excelsum, el total de imagenes es: 10\n",
      "en la Categoría: Mangifera_indica, el total de imagenes es: 10\n",
      "en la Categoría: Guazuma_ulmifolia, el total de imagenes es: 10\n",
      "en la Categoría: Pinus_radiata, el total de imagenes es: 10\n",
      "en la Categoría: Quercus_humboldtii, el total de imagenes es: 10\n",
      "en la Categoría: Cordia_alliodora, el total de imagenes es: 10\n",
      "en la Categoría: Gmelina_arborea, el total de imagenes es: 10\n",
      "en la Categoría: Albizia_guachapele, el total de imagenes es: 10\n",
      "en la Categoría: Cedrelinga_cateniformis, el total de imagenes es: 10\n",
      "en la Categoría: Erythrina_sp, el total de imagenes es: 10\n",
      "en la Categoría: Clathrotropis_brunnea, el total de imagenes es: 10\n",
      "en la Categoría: Pinus_patula, el total de imagenes es: 10\n",
      "en la Categoría: Eucalyptus_tereticornis, el total de imagenes es: 10\n",
      "en la Categoría: Couma_macrocarpa, el total de imagenes es: 10\n",
      "en la Categoría: Centrolobium_yavizanum, el total de imagenes es: 10\n",
      "en la Categoría: Xylosma_benthamii, el total de imagenes es: 10\n",
      "en la Categoría: Melicoccus_bijugatu, el total de imagenes es: 10\n",
      "en la Categoría: Jacaranda_copaia, el total de imagenes es: 10\n",
      "en la Categoría: Cedrela_odorata, el total de imagenes es: 10\n",
      "en la Categoría: Campnosperma_panamensis, el total de imagenes es: 10\n",
      "en la Categoría: Ocotea_insularis, el total de imagenes es: 10\n",
      "Número total de categorías: 29\n",
      "Suma Total de imágenes aumentadas en todas las categorías: 290\n",
      "array [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'imgs60X')\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images = []\n",
    "directories = []\n",
    "dircount = []\n",
    "prevRoot=''\n",
    "cant=0\n",
    "\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "# Definir una función para cargar imágenes de una categoría\n",
    "def cargar_imagenes_de_categoria(categoria):\n",
    "    images = []\n",
    "    cant=0\n",
    "    \n",
    "    for root, _, filenames in os.walk(os.path.join(data_dir, categoria)):\n",
    "        for filename in filenames:\n",
    "            if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "#                 cant=cant+1\n",
    "                filepath = os.path.join(root, filename)\n",
    "                image = plt.imread(filepath)\n",
    "                image_resized = resize(image, (50, 50), anti_aliasing=True, clip=False, preserve_range=True)\n",
    "                images.append(image_resized)\n",
    "#                 b = \"Leyendo...\" + str(cant)\n",
    "    return images,cant\n",
    "# Asegúrate de reemplazar 'ruta_de_salida' con la ubicación donde deseas guardar las imágenes aumentadas para cada categoría\n",
    "# ruta_de_salida = destino1\n",
    "ruta_de_salida = origen\n",
    "\n",
    "\n",
    "# Crear una instancia de ImageDataGenerator para el aumento de datos\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,          # Rango de rotación aleatoria en grados\n",
    "    width_shift_range=0.2,      # Desplazamiento horizontal aleatorio\n",
    "    height_shift_range=0.2,     # Desplazamiento vertical aleatorio\n",
    "    shear_range=0.2,            # Distorsión de corte\n",
    "    zoom_range=0.2,             # Zoom aleatorio\n",
    "    horizontal_flip=True,       # Volteo horizontal aleatorio\n",
    "    fill_mode='nearest'         # Modo de relleno\n",
    ")\n",
    "\n",
    "\n",
    "maderasCat = ['Ficus_sp','Ocotea_bofo','Qualea_acuminata','Tabebuia_rosea',\n",
    "'Cariniana_pyriformis','Tectona_grandis','Pithecellobium_dulce',\n",
    "'Peltogyne_purpurea','Anacardium_excelsum','Mangifera_indica',\n",
    "'Guazuma_ulmifolia','Pinus_radiata','Quercus_humboldtii','Cordia_alliodora',\n",
    "'Gmelina_arborea','Albizia_guachapele','Cedrelinga_cateniformis',\n",
    "'Erythrina_sp','Clathrotropis_brunnea','Pinus_patula','Eucalyptus_tereticornis',\n",
    "'Couma_macrocarpa','Centrolobium_yavizanum','Xylosma_benthamii',\n",
    "'Melicoccus_bijugatu','Jacaranda_copaia','Cedrela_odorata','Campnosperma_panamensis',\n",
    "'Ocotea_insularis']\n",
    "\n",
    "num_categorias = len(maderasCat) # variable para contar las categorias\n",
    "\n",
    "\n",
    "# Inicializa un contador para el total de imágenes aumentadas\n",
    "total_imagenes_aumentadas = 0\n",
    "\n",
    "# Dentro del bucle que aumenta las imágenes para cada categoría\n",
    "for categoria in maderasCat:\n",
    "    images_per_category, cant = cargar_imagenes_de_categoria(categoria)  # Carga las imágenes de la categoría\n",
    "    total_images_in_category = len(images_per_category)\n",
    "\n",
    "    # Inicializa un contador para las imágenes aumentadas en la categoría actual\n",
    "    total_images_aumentadas_in_category = 0\n",
    "\n",
    "    # Mientras el número de imágenes en la categoría sea menor que 10 (no 20)\n",
    "    while total_images_in_category <= 10:\n",
    "        # Genera imágenes aumentadas y agrégalas a la categoría\n",
    "        augmented_images = []\n",
    "        for image in images_per_category:\n",
    "            # Expande las dimensiones del tensor de imagen\n",
    "            image_expanded = np.expand_dims(image, axis=0)\n",
    "            for batch in datagen.flow(image_expanded, batch_size=1):\n",
    "                augmented_images.append(batch[0])\n",
    "                total_images_aumentadas_in_category += 1  # Incrementa el contador de imágenes aumentadas\n",
    "                break  # Solo necesitamos generar 1 imagen aumentada por vez\n",
    "            if total_images_aumentadas_in_category >= 10:\n",
    "                break\n",
    "\n",
    "        images_per_category.extend(augmented_images)\n",
    "        total_images_in_category = len(images_per_category)\n",
    "\n",
    "    # Restaura la forma original de las imágenes\n",
    "    images_per_category = np.array(images_per_category)\n",
    "\n",
    "    # Guarda las imágenes aumentadas en la categoría correspondiente\n",
    "    categoria_dir = os.path.join(data_dir, categoria)\n",
    "    for i, augmented_image in enumerate(images_per_category[len(images_per_category) - len(augmented_images):]):\n",
    "        filename = f'{i + 1}_augmented.jpg'\n",
    "        filepath = os.path.join(categoria_dir, filename)\n",
    "        plt.imsave(filepath, augmented_image.astype(np.uint8))\n",
    "\n",
    "\n",
    "    # Suma la cantidad de imágenes aumentadas en la categoría actual al total de imágenes aumentadas\n",
    "    total_imagenes_aumentadas += total_images_aumentadas_in_category\n",
    "    \n",
    "    # suma del array\n",
    "    dircount.append(total_images_aumentadas_in_category)\n",
    "    \n",
    "    #guardado de directorios y/o nombre de las categorias\n",
    "    directories.append(categoria)\n",
    "    \n",
    "    \n",
    "    # Imprime la cantidad de imágenes en la categoría actual\n",
    "    print(f'en la Categoría: {categoria}, el total de imagenes es: {total_images_aumentadas_in_category}')\n",
    "            \n",
    "\n",
    "    \n",
    "# Imprime el número total de categorías y la suma total de imágenes aumentadas en todas las categorías\n",
    "print(f'Número total de categorías: {num_categorias}')\n",
    "print(f'Suma Total de imágenes aumentadas en todas las categorías: {total_imagenes_aumentadas}')\n",
    "print(f'array {dircount}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b351060",
   "metadata": {},
   "source": [
    "## Creamos las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8db0ec2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad etiquetas creadas:  290\n"
     ]
    }
   ],
   "source": [
    "labels=[]\n",
    "indice=0\n",
    "for cantidad in dircount:\n",
    "    for i in range(cantidad):\n",
    "        labels.append(indice)\n",
    "    indice=indice+1\n",
    "print(\"Cantidad etiquetas creadas: \",len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a56dd5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ficus_sp\n",
      "1 Ocotea_bofo\n",
      "2 Qualea_acuminata\n",
      "3 Tabebuia_rosea\n",
      "4 Cariniana_pyriformis\n",
      "5 Tectona_grandis\n",
      "6 Pithecellobium_dulce\n",
      "7 Peltogyne_purpurea\n",
      "8 Anacardium_excelsum\n",
      "9 Mangifera_indica\n",
      "10 Guazuma_ulmifolia\n",
      "11 Pinus_radiata\n",
      "12 Quercus_humboldtii\n",
      "13 Cordia_alliodora\n",
      "14 Gmelina_arborea\n",
      "15 Albizia_guachapele\n",
      "16 Cedrelinga_cateniformis\n",
      "17 Erythrina_sp\n",
      "18 Clathrotropis_brunnea\n",
      "19 Pinus_patula\n",
      "20 Eucalyptus_tereticornis\n",
      "21 Couma_macrocarpa\n",
      "22 Centrolobium_yavizanum\n",
      "23 Xylosma_benthamii\n",
      "24 Melicoccus_bijugatu\n",
      "25 Jacaranda_copaia\n",
      "26 Cedrela_odorata\n",
      "27 Campnosperma_panamensis\n",
      "28 Ocotea_insularis\n"
     ]
    }
   ],
   "source": [
    "maderas=[]\n",
    "indice=0\n",
    "for directorio in directories:\n",
    "    name = directorio.split(os.sep)\n",
    "    print(indice , name[len(name)-1])\n",
    "    maderas.append(name[len(name)-1])\n",
    "    indice=indice+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6274a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of outputs :  29\n",
      "Output classes :  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28]\n"
     ]
    }
   ],
   "source": [
    "y = np.array(labels)\n",
    "X = np.array(images, dtype=np.uint8) #convierto de lista a numpy\n",
    "\n",
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(y)\n",
    "nClasses = len(classes)\n",
    "print('Total number of outputs : ', nClasses)\n",
    "print('Output classes : ', classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8591a1",
   "metadata": {},
   "source": [
    "## Creamos Sets de Entrenamiento y Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58faad9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [0, 290]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-25593ad43fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training data shape : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing data shape : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML36-GPU/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2172\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML36-GPU/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \"\"\"\n\u001b[1;32m    355\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML36-GPU/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 320\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [0, 290]"
     ]
    }
   ],
   "source": [
    "train_X,test_X,train_Y,test_Y = train_test_split(X,y,test_size=0.1)\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a14ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "plt.imshow(train_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(train_Y[0]))\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "plt.imshow(test_X[0,:,:], cmap='gray')\n",
    "plt.title(\"Ground Truth : {}\".format(test_Y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3f358",
   "metadata": {},
   "source": [
    "## Preprocesamos las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5296e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cb32c",
   "metadata": {},
   "source": [
    "## Hacemos el One-hot Encoding para la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the labels from categorical to one-hot encoding\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)\n",
    "\n",
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label:', train_Y[0])\n",
    "print('After conversion to one-hot:', train_Y_one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3b9aa",
   "metadata": {},
   "source": [
    "## Creamos el Set de Entrenamiento y Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45601a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar todo y crear los grupos de entrenamiento y testing\n",
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cbcac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_X.shape,valid_X.shape,train_label.shape,valid_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d936e",
   "metadata": {},
   "source": [
    "## Creamos el modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fb4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declaramos variables con los parámetros de configuración de la red\n",
    "INIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\n",
    "epochs = 400 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\n",
    "batch_size = 64 # cantidad de imágenes que se toman a la vez en memoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9fa46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "wood_model = Sequential()\n",
    "\n",
    "wood_model.add(Conv2D(32, kernel_size=(3, 3), activation='linear', padding='same', input_shape=(50,50,3)))\n",
    "wood_model.add(Conv2D(64, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "wood_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "wood_model.add(Dropout(0.25))\n",
    "\n",
    "wood_model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "wood_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "wood_model.add(Conv2D(128, kernel_size=(3, 3), activation='linear', padding='same'))\n",
    "wood_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "wood_model.add(Dropout(0.25))\n",
    "\n",
    "wood_model.add(Flatten())\n",
    "wood_model.add(Dense(1024, activation='linear'))\n",
    "wood_model.add(Dropout(0.5))\n",
    "#wood_model.add(Dense(nClasses, activation='softmax'))\n",
    "wood_model.add(Dense(nClasses, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b7a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(wood_model, to_file='model_plot3.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e4777",
   "metadata": {},
   "outputs": [],
   "source": [
    "wood_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tf.keras.optimizers.Adagrad(lr=INIT_LR, decay=INIT_LR / 100),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93771e",
   "metadata": {},
   "source": [
    "## Entrenamos el modelo: Aprende a clasificar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este paso puede tomar varios minutos, dependiendo de tu ordenador, cpu y memoria ram libre\n",
    "wood_train = wood_model.fit(train_X, train_label, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardamos la red, para reutilizarla en el futuro, sin tener que volver a entrenar\n",
    "wood_model.save(\"Wood2GPU3_mnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbb615",
   "metadata": {},
   "source": [
    "## Evaluamos la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c972e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval = wood_model.evaluate(test_X, test_Y_one_hot, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', test_eval[0])\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = wood_train.history['accuracy']\n",
    "val_accuracy = wood_train.history['val_accuracy']\n",
    "loss = wood_train.history['loss']\n",
    "val_loss = wood_train.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602eb621",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes2 = wood_model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f64984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes=[]\n",
    "for predicted_wood in predicted_classes2:\n",
    "    predicted_classes.append(predicted_wood.tolist().index(max(predicted_wood)))\n",
    "predicted_classes=np.array(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692013d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c171ef",
   "metadata": {},
   "source": [
    "## Aprendamos de los errores: Qué mejorar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(predicted_classes==test_Y)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "for i, correct in enumerate(correct[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[correct].reshape(50,50,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(maderas[predicted_classes[correct]],\n",
    "                                                    maderas[test_Y[correct]]))\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a446e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(predicted_classes!=test_Y)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "for i, incorrect in enumerate(incorrect[0:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(test_X[incorrect].reshape(50,50,3), cmap='gray', interpolation='none')\n",
    "    plt.title(\"{}, {}\".format(maderas[predicted_classes[incorrect]],\n",
    "                                                    maderas[test_Y[incorrect]]))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f01a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = [\"Class {}\".format(i) for i in range(nClasses)]\n",
    "print(classification_report(test_Y, predicted_classes, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241637ca",
   "metadata": {},
   "source": [
    "## Prediccion de una nueva imagen¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4eb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.join(os.getcwd(), 'val60X')\n",
    "imgpath = dirname + os.sep \n",
    "\n",
    "images2 = []\n",
    "filenames1 = []\n",
    "cont = 0\n",
    "\n",
    "print(\"leyendo imagenes de \",imgpath)\n",
    "\n",
    "for root, dirnames, filenames in os.walk(imgpath):\n",
    "    for filename in filenames:\n",
    "        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n",
    "            filepath = os.path.join(root, filename)\n",
    "            image = plt.imread(filepath)\n",
    "            image_resized = resize(image, (50, 50),anti_aliasing=True,clip=False,preserve_range=True)\n",
    "            images.append(image_resized)\n",
    "        filenames1.append(filename)         \n",
    "    X = np.array(images2, dtype=np.uint8) #convierto de lista a numpy\n",
    "    test_X = X.astype('float32')\n",
    "    test_X = test_X / 255.\n",
    "\n",
    "predicted_classes = wood_model.predict(test_X)\n",
    "\n",
    "for i, img_tagged in enumerate(predicted_classes):\n",
    "    cadena = filenames1[i]\n",
    "    if (cadena.count(maderas[img_tagged.tolist().index(max(img_tagged))])):\n",
    "        cont = cont + 1\n",
    "    print(filenames1[i],' -> ',maderas[img_tagged.tolist().index(max(img_tagged))])\n",
    "    \n",
    "print(\"______________________________________________________________\")\n",
    "    \n",
    "print(\"Probabilidad de Deteccion: {:.2f}%\".format((cont/(i+1)*100)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3a8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = time.time()\n",
    "print(fin-inicio) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b86e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e233777",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir carpeta_salida-7092023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60a5722",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format keras Wood2GPU3_mnist-7092023.h5 carpeta_salida-7092023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78ec0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
